{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANss1QaD819y"
      },
      "source": [
        "# (1) Multi-class Decision Tree (DT) Classification Model of AR, CG and Others (Downlink & Uplink)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpEvzO9G819z"
      },
      "source": [
        "# 1- Read the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ49cdAh819z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "### Enter your Dataset file address with csv format\n",
        "ar_data = pd.read_csv(r'AR.csv')\n",
        "cg_data = pd.read_csv(r'CG.csv')\n",
        "others_data = pd.read_csv(r'others.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set the features\n",
        "features = ['IPI', 'FS', 'IFI']\n",
        "\n",
        "ar_data = ar_data[features]\n",
        "cg_data = cg_data[features]\n",
        "others_data = others_data[features]\n",
        "\n",
        "# Label the datasets\n",
        "ar_data['Class'] = 'AR'\n",
        "cg_data['Class'] = 'CG'\n",
        "others_data['Class'] = 'Others'\n",
        "\n",
        "\n",
        "# Show the number of Samples in training Dataset\n",
        "print(f'AR samples are {ar_data.shape[0]}\\nCG samples are {cg_data.shape[0]}\\nother samples are {others_data.shape[0]}\\n###########')\n",
        "\n",
        "\n",
        "\n",
        "# Combine and shuffle the samples (Dataset of Combined Samples of AR & CG & other APPs (DS_CSACO))\n",
        "DS_CSACO = pd.concat([ar_data, cg_data, others_data]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "pprint(f'The #No of samples belong to AR is ' + str(DS_CSACO[DS_CSACO['Class']=='AR'].shape[0]))\n",
        "print(f'The #No of samples belong to CG is ' + str(DS_CSACO[DS_CSACO['Class']=='CG'].shape[0]))\n",
        "print(f'The #No of samples belong to Other Apps is ' + str(DS_CSACO[DS_CSACO['Class']=='Others'].shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dqw9Ql68190"
      },
      "source": [
        "# 2- Train the AR and CG Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKST_JAJ8191"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "##The dataset is DS_CSACO\n",
        "X = DS_CSACO[features]\n",
        "y = DS_CSACO['Class']\n",
        "\n",
        "# Class weight\n",
        "class_weights = {'AR': 1 / DS_CSACO[DS_CSACO['Class']=='AR'].shape[0],\n",
        "                 'CG': 1 / DS_CSACO[DS_CSACO['Class']=='CG'].shape[0],\n",
        "                 'Others': 1/DS_CSACO[DS_CSACO['Class']=='Others'].shape[0]}\n",
        "\n",
        "# Train AR model (Testsize = 10%, Classweight, and Criterion = 'Entropy')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=30)\n",
        "cls_model = DecisionTreeClassifier(class_weight=class_weights,criterion=\"entropy\")\n",
        "cls_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxXa2UGa8191"
      },
      "source": [
        "# 3- Evaluate the Model Before Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLxAeRMC8191",
        "outputId": "43955b49-dcbc-4ff8-9109-4844ab1a545e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AR Model Metrics: accuracy is 0.9876390605686032 |\n",
            "Precision is 0.9879819609605839 |\n",
            "recall is 0.9876390605686032 |\n",
            "f-score is 0.9876448168568386 \n",
            "It is confusion matrix:\n",
            " [[273   0   1]\n",
            " [  0 255   0]\n",
            " [  0   9 271]]\n",
            "Features are ['IPI', 'FS', 'IFI']\n"
          ]
        }
      ],
      "source": [
        "# Evluate AR & CG Model\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Evaluate AR and CG models (Accuracy, Precision, Recall, and F-Score1 + Confusion Matrix)\n",
        "accuracy, precision, recall, f1, conf = evaluate_model(cls_model, X_test, y_test)\n",
        "\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'AR Model Metrics:accuracy is {accuracy} |\\nPrecision is {precision} |\\nrecall is {recall} |\\nf-score is {f1}', '\\nIt is confusion matrix:\\n', conf)\n",
        "\n",
        "# Print features used in this training phase\n",
        "print('Features are', features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n16zmdLV8192"
      },
      "outputs": [],
      "source": [
        "# Cross Validation K-fold with K=10\n",
        "scoring = {'precision': make_scorer(precision_score, average='macro'),\n",
        "           'recall': make_scorer(recall_score, average='macro'),\n",
        "           'f1_score': make_scorer(f1_score, average='macro')}\n",
        "\n",
        "\n",
        "cv_results = cross_validate(cls_model, X, y, cv=10, scoring=scoring)\n",
        "\n",
        "print(\"Precision:\", cv_results['test_precision'].mean())\n",
        "print(\"Recall:\", cv_results['test_recall'].mean())\n",
        "print(\"F1 Score:\", cv_results['test_f1_score'].mean())\n",
        "\n",
        "print(\"**************************************************************\")\n",
        "dt_cv_scores = cross_val_score(cls_model, X, y, cv=10)\n",
        "print(\"Decision Tree - CV Scores (Accuracy):\", dt_cv_scores)\n",
        "print(\"Decision Tree - Average CV Score (Accuracy Mean):\", dt_cv_scores.mean())\n",
        "print('Features are',features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyD4fSCj8193"
      },
      "source": [
        "# 4- Draw the Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E9Q5ZGQ8193"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the AR-CG Classification Decision Tree (DT) Model\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(cls_model, feature_names=features, class_names=['AR', 'CG', 'Others'], filled=True)\n",
        "plt.title(\"AR-CG Classification  Decision Tree\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qstiaNry8193"
      },
      "source": [
        "# 5- Improved The Model using GridSearch Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR-SvtNi8193"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# DS_CSACO dataset with 'IPI','FS','IFI' features and Class\n",
        "X = DS_CSACO.drop('Class', axis=1)\n",
        "y = DS_CSACO['Class']\n",
        "\n",
        "\n",
        "# Define the parameter grid (Tables.I of the paper)\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30,40],\n",
        "    'min_samples_split': [2, 5, 10,20],\n",
        "    'min_samples_leaf': [1, 2, 4,6],\n",
        "    'criterion': ['entropy','gini']\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize GridSearch with cross-validation\n",
        "grid_search = GridSearchCV(estimator=cls_model, param_grid=param_grid, cv=10, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Train the model with the best parameters\n",
        "cls_model_optimized = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = cls_model_optimized.predict(X)\n",
        "print(classification_report(y, predictions))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOG43TT78196"
      },
      "source": [
        "# 6- **Test the trained model and optimized model (6-1) Load the Test Dataset & (6-2) Test the model **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq5sOD8e8196"
      },
      "source": [
        "# 6-1- Load the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rDXbtyx8196"
      },
      "outputs": [],
      "source": [
        "# Load the test dataset (Mentioned in Table (IV) of the Paper)\n",
        "AR_Test = pd.read_csv(r'AR-Test.csv')\n",
        "CG_Test = pd.read_csv(r'CG_Test.csv')\n",
        "Other_Test = pd.read_csv(r'Other_Test.csv')\n",
        "# ** Notice: Test the Model with direction considering (DL or UL)\n",
        "\n",
        "# Set the features of teh test dataset and label them\n",
        "AR_Test = AR_Test[features]\n",
        "AR_Test['Class'] = 'AR'\n",
        "\n",
        "CG_Test = CG_Test[features]\n",
        "CG_Test['Class'] = 'CG'\n",
        "\n",
        "Other_Test = Other_Test[features]\n",
        "Other_Test['Class'] = 'Others'\n",
        "# ** Notice: Pay attention to the feature variable name to match the features of the test dataset\n",
        "\n",
        "# Combine the Test Dataset\n",
        "DT_Test =  pd.concat([AR_Test,CG_Test,Other_Test],sort=False).sample(frac=1, random_state=30).reset_index(drop=True)\n",
        "\n",
        "\n",
        "X_test = DT_Test[features]\n",
        "y_test = DT_Test['Class']\n",
        "\n",
        "# print the number of each sample in the Test Dataset\n",
        "print('No# of AR samples',DT_Test[DT_Test['Class']=='AR'].shape,\n",
        "      '\\nNo# of CG samples-->',DT_Test[DT_Test['Class']=='CG'].shape,\n",
        "      '\\nNo# of Other Apps samples-->',DT_Test[DT_Test['Class']=='Others'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6iw7rSm8197"
      },
      "source": [
        "# 6-2- **Test and evaluate the Model**\n",
        "> *(6-2-1) cls_model (Simple model without Hyperparameter Tunning) (6-2-2)  cls_model_optimized (Optimized model without Hyperparameter Tunning by search grid)*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6-2-1- **Test cls_model**"
      ],
      "metadata": {
        "id": "18MWYzEvMoFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGtkWanF8197"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Make predictions with the model ************ cls_model & cls_model2\n",
        "predictions = cls_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# ROC Curve (if y_test is binary or multiclass)\n",
        "# Convert y_test to a binary format\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Print the features used for classification\n",
        "print('Features are',features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EpCcyFy8197"
      },
      "source": [
        "6-2-1- **Test cls_model_optimized**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GrEuBB98197"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions with the model ************ cls_model & cls_model2\n",
        "predictions = cls_model_optimized.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# ROC Curve (if y_test is binary or multiclass)\n",
        "# Convert y_test to a binary format\n",
        "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
        "n_classes = y_test_bin.shape[1]\n",
        "\n",
        "# Print the features used for classification\n",
        "print('Features are',features)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
